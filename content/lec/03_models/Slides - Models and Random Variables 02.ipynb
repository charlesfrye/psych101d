{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"../../shared/img/banner.svg\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Models and Random Variables 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from shared.src import quiet\n",
    "from shared.src import seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "import daft\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc3 as pm\n",
    "import scipy.special\n",
    "import scipy.stats\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def sample_from(model, n, filt=10):\n",
    "    with model:\n",
    "        samples = pm.sample(chains=1, draws=n * filt)[::filt]\n",
    "    [samples.remove_values(name) for name in samples.varnames if \"_log__\" in name]\n",
    "    \n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def samples_to_dataframe(samples):\n",
    "    return pd.DataFrame([sample for sample in samples])\n",
    "\n",
    "def add_counts(data):\n",
    "    data[\"count\"] = np.ones(len(data))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## There are many kinds of random variables available in `pymc`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The traditional way of learning them goes like this:\n",
    "\n",
    "I tell you the name, then I tell you a formula for the distribution of the random variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Remember that, for all kinds of random variable, the distribution is what the histogram is approximating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> A random variable is said to have the _Laplace_ distribution with mean $\\mu$ and scale $\\lambda$ if the distribution of the variable is given by\n",
    "\n",
    "$$\n",
    "p(x ; \\lambda) = \\frac{\\lambda}{2}\\mathrm{e}^{-\\lambda|x-\\mu|}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "and then we would look at a graph of the formula for some choices of the parameter $\\lambda$, then start deriving properties of this random variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### In this lecture, we will learn about them by building them up from smaller parts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We'll start with simple random variables.\n",
    "\n",
    "By combining them into more complicated models, we'll discover new random variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Let's start where probability theory began: dice games."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The first mathematical works on probability were called, in Latin, _Liber de Ludo Aleae_, or _Book on Games of Chance_, by Gerolamo Cardano (written c. 1564, published 1663) and _De Ratiociniis in Ludo Aleae_ or _Reasoning in Games of Chance_, by Christian Huygens (1657)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "Image(\"./img/cardano.jpg\", width=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Cardano was something of a mathematical bad boy: a proponent of such scandalous ideas as negative, even imaginary numbers, and constantly in dire financial straits. He used his knowledge of probability to earn money at games of dice. The publication of his book was delayed because it included a section on ways to cheat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### So we begin with a humble random variable: the `DiscreteUniform`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`Discrete` means you can count the number of possible values, as when drawing from a deck of cards or guessing the number of avocados produced in a year in California.\n",
    "\n",
    "`Uniform` means that each outcome is equally likely, as when drawing from a shuffled deck of cards or looking at the position of an air molecule in a room."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The traditional six-sided die is a `DiscreteUniform` with six outcomes, numbered `1` through `6`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "d6_model = pm.Model()\n",
    "\n",
    "with d6_model:\n",
    "    pm.DiscreteUniform(name=\"U\", lower=1, upper=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "data = samples_to_dataframe(sample_from(d6_model, 1000, filt=25))\n",
    "\n",
    "data.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The resulting frequencies are roughly even, or `Uniform`, as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "add_counts(data)\n",
    "data.groupby(\"U\").sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## We can simulate collections of random variables with `shape`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Just before Cardano's and Huygens's books were published, two prominent French mathematicians,\n",
    "Blaise Pascal (famous for [Pascal's wager](https://plato.stanford.edu/entries/pascal-wager/) that God exists; betting was popular then) and Pierre de Fermat exchanged some letters comparing their notes on games of chance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Their letters were occasioned by a question from another libertine-mathematician, alias Chevalier de Méré.\n",
    "\n",
    "His (incorrect) rules for reasoning with probability told him that if he bet even money that he could roll two sixes, (aka \"ringing the bell\" or _sonnez_) at least once in 24 rolls of a pair of dice, he would come out ahead.\n",
    "Experience had shown that he lost money unless he rolled 25 times.\n",
    "\n",
    "Let's see if we can simulate this _sonnez_ game and verify the Chevalier's claims."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We will use `DiscreteUniform` again.\n",
    "\n",
    "This time, however, we want to simulate the process of rolling multiple pairs of dice.\n",
    "\n",
    "To achieve this, we'll add a `shape` argument to our definition of the variable. The result will be outputs that are arrays whose shape is equal to the value of the `shape` argument. This is more efficient than creating `num_rolls * 2` separate variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sonnez_model = pm.Model()\n",
    "num_rolls = 24\n",
    "\n",
    "with sonnez_model:\n",
    "    pm.DiscreteUniform(name=\"rolls\", lower=1, upper=6, shape=(num_rolls, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Two `pyMC` tricks are happening here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. You might object that, in a real game of _sonnez_, we'd stop whenever a _sonnez_ was rolled, so this model doesn't really simulate our process. For technical reasons, it's very hard for `pyMC` to simulate situations where _the existence of certain variables is determined by chance_. For example, the 24th roll only happens if the first 23 rolls were all failures, which is determined by chance. Instead, what we typically do is simulate all variables that might be present, then ignore values as needed. This will be important for the lab.\n",
    "\n",
    "For example, if we were simulating our winnings from _sonnez_, we would ignore any cases where we rolled two or more _sonnez_s in a set of 24 rolls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "2. Second, you might wonder why we bother with `shape` here. Couldn't we just take the `d6_model` above, take `num_rolls * 2 * num_samples` samples, and use those as our rolls? Unfortunately, the samples from `pyMC` aren't _independent_ -- if you look closely, you'll see that streaks are more common than you'd expect by chance. This is especially bad for a model of _sonnez_. We'll talk more about what sample dependence means for using `pyMC` correctly later on in the course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "raw_roll_data = samples_to_dataframe(sample_from(sonnez_model, 25000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "for ii in range(num_rolls):\n",
    "    raw_roll_data[\"roll_\" + str(ii)] = raw_roll_data[\"rolls\"].apply(lambda lst: lst[ii])\n",
    "    \n",
    "roll_data = raw_roll_data.drop(\"rolls\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "roll_data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "With our rolls in hand, we first move through each roll, determining whether it was a _sonnez_.\n",
    "We use `apply` to apply the same function, `is_success`, to each roll."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def is_success(roll):\n",
    "    return roll[0] == roll[1] == 6\n",
    "\n",
    "success_data = pd.DataFrame()\n",
    "for ii in range(num_rolls):\n",
    "    success_data[\"success_on_roll_\" + str(ii)] = roll_data[\"roll_\" + str(ii)].apply(is_success)\n",
    "\n",
    "success_data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Then, we can figure out which batches of 24 rolls included a _sonnez_ by `apply`ing the `max` function to each row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "success_in_batch = success_data.apply(max, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "success_in_batch.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "chance_success = success_in_batch.describe().freq / success_in_batch.describe()[\"count\"]\n",
    "chance_success"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "At least once when I ran this, I got an incorrect answer: it looked like betting you can get a _sonnez_ in 24 rolls was a money-making, rather than money-losing, bet!\n",
    "Remember never to trust a single point value calculated from data (i.e., one without error bars), and that bootstrapping is still a valid way to do inference on data from `pyMC` models!\n",
    "\n",
    "To really draw an inference, we'd want to bootstrap our samples many times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "success_in_batch.sample(frac=1, replace=True).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Counting successes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In another game, we might win more money the more times we roll a _sonnez_.\n",
    "\n",
    "If we want to know our odds of success or average winnings in that game, we want to add up our _sonnez_ rolls in each batch (we use `sum` instead of `max`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "number_success = success_data.apply(sum, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(number_success, bins=range(max(number_success) + 1), align=\"left\", normed=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We might be happy to stop here, but when calculating by hand, it's good to have shortcuts for these sorts of things.\n",
    "\n",
    "So Jakob Bernoulli, building off the work of Pascal and Cardano, was able to derive the general shape of this distribution, as a function of both the number of rolls and the chance of the outcome of interest.\n",
    "\n",
    "In Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def binomial_pmf(k, N, q):\n",
    "    chance_of_k_successes_in_a_row = (q ** k)\n",
    "    chance_of_all_failures_after = (1 - q) ** (N - k)\n",
    "    number_of_ways_to_scramble = scipy.special.binom(N, k)\n",
    "    return number_of_ways_to_scramble * chance_of_k_successes_in_a_row * chance_of_all_failures_after"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "and math:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### The Binomial($N$, $q$) Distribution: $$p(k) = \\color{ForestGreen}{\\binom{N}{k}} q^{k}(1-q)^{N-k}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "where $N$ is the number of attempts and $q$ is the chance of success on any given attempt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The quantity in $\\color{ForestGreen}{\\text{green}}$ is the _binomial coefficient_ (discovered by Cardano in a different area of mathematics!), implemented in Python as `scipy.special.binom`.\n",
    "\n",
    "Loosely, it counts the number of ways we can succeed `k` times in `N` tries. `k` in a row at the start, one failure then `k` successess, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can estimate `q` from our data. Can you guess how?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "q = np.mean(np.mean(success_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ks = np.arange(max(number_success) + 2)\n",
    "plt.hist(number_success, bins=ks, align=\"left\", normed=True,\n",
    "         histtype=\"step\", lw=4);\n",
    "\n",
    "plt.plot(ks, binomial_pmf(ks, num_rolls, q), lw=4, marker='.', markersize=24);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "And, as promised, this formula gives a good match to our data histogram.\n",
    "\n",
    "Go back and change the definition of `is_success` to something else -- maybe check if any number rolled is even, or if the sum of the rolls is `7`.\n",
    "\n",
    "The shape of the distribution will change, but the shape given by `biniomial_pmf` will track it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## We can count successes with `pm.Binomial`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Rather than modeling our _sonnez_ game with `DiscreteUniform`s representing dice rolls, we could instead model it with a `Binomial` representing the number of _sonnez_s directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "binomal_sonnez_model = pm.Model()\n",
    "\n",
    "with binomal_sonnez_model:\n",
    "    pm.Binomial(name=\"num_sonnez\", n=24, p=q)  # some use p, some use q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "binomial_sonnez_data = samples_to_dataframe(sample_from(binomal_sonnez_model, 10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "binomial_sonnez_data = add_counts(binomial_sonnez_data)\n",
    "\n",
    "binomial_sonnez_counts = binomial_sonnez_data.groupby(\"num_sonnez\")\\\n",
    "    .sum() / len(binomial_sonnez_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(number_success, bins=ks, align=\"left\", normed=True,\n",
    "         histtype=\"step\", lw=4);\n",
    "plt.hist(binomial_sonnez_data[\"num_sonnez\"], bins=ks,\n",
    "         normed=True, align='left',\n",
    "         histtype=\"step\", lw=4);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Modeling always requires trade-offs, like between flexibility and efficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "By making an assumption about the phenomenon we are modeling, we were able to simplify our model: instead of simulating each die roll, we can just simulate how many were _sonnez_s.\n",
    "\n",
    "In this case, this buys us\n",
    "1. A smaller dataset. In `success_model`, each row has 48 numbers. In `binomial_sonnez_model`, there's just 1. Imagine the savings if we were playing a game with 1,000,000 rolls!\n",
    "1. Less work. Our data is already in the form we want to work with, so the analysis is simpler: just `add_counts` and `groupby`.\n",
    "\n",
    "but at a price: we no longer have a detailed model. So if the context changes and we are instead interested in how many streaks of three `3`s there are, or how often an odd number is rolled, we'd have to build a new model, rather than re-analyzing the output of an old model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "When we're in an exploratory phase or another rapidly-changing environment, keeping a flexible model is preferred. Once we've nailed down exactly what we'd like to model and understand, we can switch over to something more efficient and limited."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## We can model the rain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "Image('./img/umbrella.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Say it is raining. How many drops are hitting your umbrella each second? How much does that count vary?\n",
    "\n",
    "With a bit of cleverness, we can answer this question using the `Binomial`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Divide the area your umbrella into some number of small pieces and, for each piece, record whether at least one raindrop hit there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "Image('./img/umbrella_top.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Each area is a like a `DiscreteUniform` on `0` (no drop) and `1` (at least 1 drop). The raindrops don't have much effect on each other, so they're like our separate die rolls, or independent samples from `DiscreteUniform`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "That makes this example a `Binomial`. The smaller we make the pieces, the less likely any individual piece is to have more than 1 drop hit it, and so the closer we get to counting the raindrops."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's say that when we split the umbrella into `16` pieces, the chance any individual piece gets at least one rain drop in a second is `1 / 12` (it's a very light drizzle)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "raindrops_model = pm.Model()\n",
    "\n",
    "num_pieces = 16\n",
    "q = 1 / 2\n",
    "\n",
    "with raindrops_model:\n",
    "    pm.Binomial(name=\"num_drops\", n=num_pieces, p=q)\n",
    "\n",
    "raindrops_data = samples_to_dataframe(sample_from(raindrops_model, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(raindrops_data[\"num_drops\"],\n",
    "         bins=range(max(raindrops_data[\"num_drops\"]) + 2),\n",
    "         histtype=\"step\", linewidth=4, align=\"left\", normed=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "If we want more accuracy, we can split into smaller pieces (say, split each piece in 1/2 or in quarters).\n",
    "\n",
    "Then the number of trials would go up (double, quadruple) and the chance of a drop hitting would go down (1/2, 1/4).\n",
    "\n",
    "Let's simulate what happens to the number of drops we observe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "precise_raindrops_model = pm.Model()\n",
    "\n",
    "with precise_raindrops_model:\n",
    "    pm.Binomial(name=\"num_drops\", n=num_pieces * 100 , p=q / 100 ) # 100 times finer grid\n",
    "\n",
    "precise_raindrops_data = samples_to_dataframe(sample_from(precise_raindrops_model, 10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(raindrops_data[\"num_drops\"],\n",
    "         bins=range(max(raindrops_data[\"num_drops\"]) + 2),\n",
    "         histtype=\"step\", linewidth=4, align=\"left\", normed=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(precise_raindrops_data[\"num_drops\"],\n",
    "         bins=range(max(precise_raindrops_data[\"num_drops\"]) + 2),\n",
    "         histtype=\"step\", linewidth=4, normed=True, align=\"left\",\n",
    "         alpha=0.85, color=\"C3\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The Poisson distribution lets us model counts of events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Another French mathematician, [Siméon Denis Poisson](https://en.wikipedia.org/wiki/Sim%C3%A9on_Denis_Poisson), studied this sort of problem, in 1837. In his case, he was trying to model the rate and occurrence of wrongful convictions (somewhat more noble than gambling).\n",
    "\n",
    "With some clever mathematics, he was able to demonstrate that the shape of the distribution is given by the following Python function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def poisson_pmf(k, mu):\n",
    "    return np.exp(-mu) * mu ** k / math.factorial(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or, in traditional math terms:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### The Poisson Distribution: $$p(k; \\mu) = \\mathrm{e}^{-\\mu} \\cdot \\frac{\\mu^k}{k!}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "where `mu` aka $\\mu$ is the average value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can verify this by comparing the distribution to our sample histograms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "average_number_drops = np.mean(precise_raindrops_data[\"num_drops\"])\n",
    "poisson_pmf = scipy.stats.poisson(mu=average_number_drops).pmf\n",
    "# scipy.stats has lots of distributions implemented, so we don't have to write out own!\n",
    "\n",
    "ks = range(max(precise_raindrops_data[\"num_drops\"]) + 2)\n",
    "plt.plot(ks, poisson_pmf(ks), linewidth=4, marker=\".\", markersize=24);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This model of the rain has at least one distinct advantage over the binomial model: it's easier to match it to data.\n",
    "\n",
    "The parameter, `mu`, is just the average number of raindrops in a second.\n",
    "We could count raindrops for 60 seconds, divide by 60, and then be done.\n",
    "\n",
    "Compare that to the parameters of the binomial model, `n` and `p`.\n",
    "For the model to be accurate, `n` must be large and `p` must be small.\n",
    "So to actually measure that `p` accurately,\n",
    "we'd need to determine the chance of a raindrop falling on a very small area.\n",
    "Since that chance is small, we'd need many trials to determine the chance accurately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "But again, we lose the ability to model what's happening on the individual parts of the umbrella, so if we later wanted to know, say, how big a difference in raindrop counts to expect on one half of the umbrella versus the other, a `Poisson` model wouldn't cut it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Raindrops another way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's consider another, more detailed model of the rain.\n",
    "\n",
    "Instead of just counting raindrops, let's time them.\n",
    "Every time a drop hits, we start a stopwatch.\n",
    "When another drop hits, we stop the stopwatch and log the time.\n",
    "\n",
    "That is, we measure the time in between rain drops.\n",
    "In general, the amount of time between events is called an _inter-event interval_,\n",
    "so we'll call the value we're measuring the _inter-drop interval_.\n",
    "\n",
    "But what should the distribution of the times between rain drops be?\n",
    "Creating a more detailed model requires us to use more sophisticated tools and make additional assumptions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In building our binomial model, we already assumed that the number of raindrops in one area had no effect on the raindrops in another area.\n",
    "Let's also assume that the raindrops at one point in time have no effect on raindrops at another point in time.\n",
    "\n",
    "This is different from the behavior of, say, a bus.\n",
    "If the 6 bus arrives, on average, at the corner of Telegraph and Haste every 10 minutes, and no bus has arrived for 9 minutes, you're more likely to see one in the next minute than in the minute right after a bus arrives.\n",
    "\n",
    "It seems plausible, on the other hand,\n",
    "that raindrops are not like buses.\n",
    "They are, unfortunately for many weddings, not scheduled\n",
    "and seem to fall relatively independently of one another."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "There are many phenomena that behave (approximately) this way:\n",
    "the time in between customer orders on Amazon (or orders of a particular product),\n",
    "the time between radioactive decay events,\n",
    "the time for a Bitcoin transaction to be completed (more on that later!).\n",
    "\n",
    "They are known as _memoryless_ phenomena.\n",
    "It can be shown that there is only one distribution\n",
    "for memoryless processes:\n",
    "the `Exponential` distribution.\n",
    "\n",
    "It has one parameter, the rate, `lambda` aka $\\lambda$, aka `lam`.\n",
    "It is the average number of events per unit time, which we computed for our data above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "raindrop_time_model = pm.Model()\n",
    "\n",
    "with raindrop_time_model:\n",
    "    pm.Exponential(name=\"interdrop_intervals\", lam=average_number_drops, shape=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "raindrop_time_data = samples_to_dataframe(sample_from(raindrop_time_model, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(raindrop_time_data.sample()[\"interdrop_intervals\"], alpha=0.1, color=\"k\", normed=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Notice the exponential shape of the histograms -- that's where this random variable type gets its name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Does this model of the rain match up with our previous models, which used the `Binomial` and the `Poisson` to count rain drops?\n",
    "\n",
    "Because the `Poisson` model was less detailed, we can't probe it for raindrop arrival times -- that information isn't a part of that model.\n",
    "But we can count how many rain drops occurred in each second of our `Exponential` model and see whether the distribution matches.\n",
    "\n",
    "Let's first visualize the raindrop arrivals as a sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "raindrop_times = np.cumsum(raindrop_time_data.sample()[\"interdrop_intervals\"].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plt.vlines(raindrop_times[:100], 0, 0.1, alpha=0.5, color=\"#3b7ea1\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can use the `hist` function to compute the number of raindrops in each one-second bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "counts, _, _ = plt.hist(raindrop_times, bins=range(math.ceil(max(raindrop_times) + 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "And then apply the histogram to those counts to see the distribution of numbers of raindrops per second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(counts,\n",
    "         bins=range(math.ceil(max(counts) + 2)), normed=True, align=\"left\", histtype=\"step\", lw=4);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Which is well-approximated by our `Poisson` probability mass function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(scipy.stats.poisson.pmf(range(math.ceil(max(counts) + 2)), mu=np.mean(counts)),\n",
    "         color=\"C1\", lw=4, marker='.', markersize=24);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Try adjusting the original `q` parameter for the `Binomial` model of the rain and re-executing all of the code.\n",
    "\n",
    "Reducing it to something like `1 / 20` will let you see the other extreme of how a `Poisson`-distributed random variable can be distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ask not for whom the bell curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "One of the powerful ideas examined in this course is to _apply our modeling methods to our inference tools_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "As an example, consider what happens when we take the mean of some data generated by measuring a process. We would like to infer that the true mean of the process is close to the mean we measured. We can use our modeling tools to understand this inference: how close it likely is, the chance we are off by at least some amount, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Every time we take a sample, we get a different value for the mean, and so the process of sampling the values of a random variable, or measuring the values of some phenomenon, is _also a phenomenon we can model with random variables_, where one of the random variables of interest is the _mean of the other random variables in the model_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The distribution of the mean, measured across repeated measurements, will be called the _sampling distribution of the mean_, and statistics is, in one sentence, the mathematical study of sampling distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Normal distributions make statistics easy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This presents a problem: we've spent some time learning all of these distributions for our random variables, and now I'm telling you we need to learn also the sampling distributions for all of the statistics we care about (mean, standard deviation, etc.) Sounds like a tall order!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "So statistics would be even harder than it is if it weren't for a cool fact:\n",
    "almost all of those distributions have the same shape: the _bell curve_.\n",
    "\n",
    "We'll demonstrate this below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def build_mean_model(random_variable, parameters, sample_size=30):\n",
    "\n",
    "    means_model = pm.Model()\n",
    "\n",
    "    with means_model:\n",
    "        for ii in range(sample_size):\n",
    "            random_variable(name=\"sample_\" + str(ii), **parameters)\n",
    "            \n",
    "    return means_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# poisson\n",
    "poisson_rv, poisson_params = pm.Poisson, {\"mu\": 1.}\n",
    "\n",
    "# exponential\n",
    "exponential_rv, exponential_params = pm.Exponential, {\"lam\": 0.5}\n",
    "\n",
    "# binomial\n",
    "binomial_rv, binomial_params = pm.Binomial, {\"n\": 2, \"p\": 0.1}\n",
    "\n",
    "poisson_mean_model = build_mean_model(poisson_rv, poisson_params)\n",
    "exponential_mean_model = build_mean_model(exponential_rv, exponential_params)\n",
    "binomial_mean_model = build_mean_model(binomial_rv, binomial_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "means_data = samples_to_dataframe(sample_from(poisson_mean_model, 500))\n",
    "\n",
    "samples = np.asarray(means_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "sample_cts = [1, 2, 5, 10, 20, 30]\n",
    "\n",
    "def setup_clt_plot(sample_cts):\n",
    "    nrows = 2\n",
    "    ncols = len(sample_cts) // nrows\n",
    "    aspect = 1 / (ncols / 2)\n",
    "    f, axs = plt.subplots(figsize=(10, 10 * aspect), nrows=nrows, ncols=ncols,\n",
    "                          sharex=True, sharey=True)\n",
    "    return f, axs\n",
    "\n",
    "f, axs = setup_clt_plot(sample_cts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "mean = lambda xs: np.mean(xs, axis=1)\n",
    "var = lambda xs: np.var(xs, axis=1)\n",
    "\n",
    "def clt_plot(samples, sample_cts, axs, stat_func=mean, lims=[0, 5]):\n",
    "\n",
    "    for ax, sample_ct in zip(axs.flatten(), sample_cts):\n",
    "        ax.hist(np.mean(samples[:, :sample_ct], axis=1), #bins=np.linspace(*lims, 10),\n",
    "                 histtype=\"step\", align=\"mid\", lw=2, normed=True);\n",
    "\n",
    "    for ax, sample_ct in zip(axs.flatten(), sample_cts):\n",
    "        xs = np.linspace(*lims, num=100)\n",
    "        ax.plot(xs,\n",
    "                scipy.stats.norm(np.mean(stat_func(samples[:, :sample_ct])),\n",
    "                                 np.std(stat_func(samples[:, :sample_ct]))).pdf(xs),\n",
    "                lw=2)\n",
    "        ax.set_title(\"Sample Size: {0}\".format(sample_ct))\n",
    "        \n",
    "clt_plot(samples, sample_cts, axs, lims=[0, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The Normal distribution shows up everywhere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The fact that the normal distribution shows up for sampling distributions is very important.\n",
    "\n",
    "So important that that fact has a name: the _Central Limit Theorem_. Here \"central\" means \"essential\" or \"important\", as in \"the central point of my essay\". It was described by mathematician [J.F.C. Gauss](https://en.wikipedia.org/wiki/Carl_Friedrich_Gauss) in [1809](https://en.wikipedia.org/wiki/Normal_distribution#History).\n",
    "For that reason, it's sometimes called the _Gaussian distribution_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Gauss and his distribution are important enough to have once graced the 10 DM bill, before the advent of the euro:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "Image(\"./img/ten_deutsche_marks.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "source: https://www.kleinbottle.com/gauss.htm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The normal distribution has a somehwat mysterious-looking form when you first look at it:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### The Normal Distribution: $$p(x; \\mu, \\sigma) = \\frac{1}{\\sqrt{2 \\pi}\\sigma} \\mathrm{e}^{\\frac{-(x -\\mu)^2}{2\\sigma^2}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "To make it more comprehensible, let's write it out in Python, giving the variables useful English names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def normal_pdf(x, mu, sigma):\n",
    "    normalizer = 1 / (np.sqrt(2 * pi) * sigma)\n",
    "    distance_from_mean = np.square(x - mu)\n",
    "    scale_of_distances = 2 * sigma ** 2\n",
    "    return normalizer * np.exp(-distance_from_mean / scale_of_distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Let's review our random variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- `pm.Binomial`: `N`, `q`. Total number of successes in `N` attempts if each attempts has a chance `q` of success. Examples: number of A's in a semester, number of grants that will be approved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- `pm.Poisson`: `mu`. Total number of successes when individual chance is low, but there are many attempts. Examples: number of fish (_poisson_) that jump above the water in a second, number of Prussian soldiers killed by horse kicks on a given day. Result of taking `N` very large and `q` very small for a `Binomial`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- `pm.Exponential`: `lam`. Elapsed time between events for a memoryless process. Time between Prussian soldiers killed by horse kicks. Time between radioactive decay events. If we count the events, we get a `Poisson`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- `pm.Normal`: `mu`, `sigma`. Anything affected by a large number of uncontrolled, unrelated factors of around the same size. Human heights within a population. Many scientific measurements. `Binomial` with a large enough `N`. `Poisson` with a large `lam`."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
