{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"../../shared/img/slides_banner.svg\" width=2560></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Midterm Review of Modeling Concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from shared.src import quiet\n",
    "from shared.src import seed\n",
    "from shared.src import style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "import daft\n",
    "import IPython.display as display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc3 as pm\n",
    "import seaborn as sns\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "sns.set_context(\"notebook\", font_scale=1.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import shared.src.utils.util as shared_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# We make _Models_ out of _Random Variables_ that have _Distributions_\n",
    "\n",
    "Our core activity is to build models.\n",
    "When I say \"model\", I usually mean an instance of the `pm.Model` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "type(pm.Model())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### A model is a collection of interrelated random variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### A random variable is anything with a _distribution_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Literally: a `pm.Model` is made up of things that have `pm.Distribution`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "(isinstance(pm.Normal.dist(mu=0, sd=1), pm.Distribution),\n",
    " isinstance(pm.DiscreteUniform.dist(lower=0, upper=1), pm.Distribution))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "That's why the models we are building are sometimes called _probabilistic models_:\n",
    "they are made up of things that have _probability distributions_ associated with them.\n",
    "\n",
    "Technically, `Flat` and `HalfFlat` are distributions but not probability distribtions,\n",
    "and so any model with those kinds of RVs in it is not a true probabilistic model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Random does not mean arbitrary, nor does it mean without any structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In colloquial, everyday speech,\n",
    "_random_ is often taken to mean either\n",
    "_it doesn't matter which value is chosen_, as in \"pick a card, any card, at random\"\n",
    "or\n",
    "_there is no structure to the values_, as in \"the power outages are occurring at random\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In this class, random means something different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# There are two kinds of random variables.\n",
    "\n",
    "Both have distributions, but those distributions mean different things."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Sometimes, a random variable is a variable whose value is different each time we measure it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "  - **Result of a dice roll**: dependent on the precise position of my hand, the air currents, the shape of the table (lec03, lab03)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "  - **Score of a participant on a task**: dependent on their attentiveness, their diligence, their skill at the task, and indirectly on any factors that determine those factors (hw02, lab06)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "  - **Response of a patient to a drug**: dependent on their genetic makeup, on their environment, on their mental state, on the quality of the pills they are given (hw03)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Can you think of any other examples from the lectures, homework, or labs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### In this case, the distribution describes the frequency we observe all possible values of the variable.\n",
    "\n",
    "It is a function that, for each possible value of the variable,\n",
    "gives a number that tracks the frequency that that value is observed:\n",
    "it is larger when that value of the variable is observed with higher frequency\n",
    "and smaller when that value of the variable is observed with lower frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def make_normal_distribution(mu=0, sd=1):\n",
    "    logp = pm.Normal.dist(mu=mu, sd=sd).logp\n",
    "    # technically, pyMC works with _logs of distributions_,\n",
    "    #  so we have to \"remove the log\" with an exponential\n",
    "    def compute_normal_distribution(x):\n",
    "        return np.exp(logp(x).eval())\n",
    "    return compute_normal_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "standard_normal_distribution = make_normal_distribution(mu=0, sd=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "standard_normal_distribution_scipy = scipy.stats.norm(loc=0, scale=1).pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "assert np.isclose(standard_normal_distribution_scipy(-10),\n",
    "                  standard_normal_distribution(-10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For example, we might measure the amplitudes of a particular \"brain wave\"\n",
    "in study participants who are quietly sitting in a chair, focusing on their breathing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "By \"amplitude of a brain wave\" I mean the peak amplitude in a given frequency band of an EEG measurement,\n",
    "e.g. the 4-16 Hz band.\n",
    "A participant focusing on their breathing would be engaging\n",
    "what is called by some the\n",
    "[default-mode network](https://www.ncbi.nlm.nih.gov/pubmed/26738043)\n",
    "of brain regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "f, ax, = plt.subplots(figsize=(12, 6))\n",
    "xs = np.linspace(-5, 5, 1000)\n",
    "ax.plot(xs, standard_normal_distribution(xs), lw=4);\n",
    "ax.set_xlabel(\"Brain Wave Amplitude Observed\");\n",
    "ax.set_ylabel(\"Proportional to Frequency\\nBrain Wave Amplitude is Observed\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "What this distribution is saying is that it is _less frequently the case_ that values around 3 are observed,\n",
    "while it is _more frequently the case_ that the values around 1 are observed\n",
    "and _even more frequently the case_ that values around 0 are observed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Or, more generically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "f, ax, = plt.subplots(figsize=(12, 6))\n",
    "xs = np.linspace(-5, 5, 1000)\n",
    "ax.plot(xs, standard_normal_distribution(xs), lw=4);\n",
    "ax.set_xlabel(\"Value Observed\");\n",
    "ax.set_ylabel(\"Proportional to Frequency\\nValue is Observed\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## In probability terms, these distributions tell us how _probable it is to observe a value_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## This type of random variable most often appears in the _likelihood_ of our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The _likelihood_ is the piece of our model that connects to observable data,\n",
    "and so those random variables usually represent the uncertainty in the frequency with which\n",
    "values will be observed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Sometimes, a random variable is a variable whose value is fixed, but unknown to us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "  - The **average response of patients to a drug**, the **variability in patient responses to drugs**\n",
    "      - The average effect of caffeine on alertness (lab03)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "  - The **probability of an outcome**, e.g. any of the outcomes we've considered so far\n",
    "      - The probability a hip-hop lyric will contain positive sentiment about Donald Trump (lec06)\n",
    "      - The probability that a statistical test will give a negative result (lab05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Can you think of any other examples from the lectures, homework, or labs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In some cases, these variables are the _parameters of a population distribution_.\n",
    "\n",
    "They are often the _parameters of observable variables_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## For this type of random variable, the distribution no longer describes the _frequency_ with which something is _observed_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For one, this is usually something we cannot or don't expect to observe. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We typically cannot observe the mean in a population, because we cannot collect up the entire population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We cannot \"observe\" the average effect of a drug on patients.\n",
    "We cannot \"observe\" the chance that a test gives a negative result.\n",
    "\n",
    "Instead, we observe the effect on a bunch of patients or the result of many tests,\n",
    "and we use those observations to estimate the unknown quantity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "It's also not something that happens over and over again.\n",
    "\n",
    "There is only one \"average response\",\n",
    "unlike \"response of a single patient\",\n",
    "and so we can't talk about the frequency with which values occur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "So in the case of this type of random variable,\n",
    "what does the distribution correspond to?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## For these random variables, the distribution tracks the _plausibility of a claim_.\n",
    "\n",
    "That is, for every possible value of the unknown quantity,\n",
    "the distribution is a function that returns a value that is\n",
    "_higher when the claim is more plausible_\n",
    "and _lower when the claim is less plausible_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "So when we say that a distribution represents \"our beliefs\",\n",
    "this is what we mean:\n",
    "we _believe_ that certain claims are more plausible and certain claims are less plausible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Returning to our brain wave example, we might think that the true\n",
    "mean of the brain wave amplitude in the population we are measuring is something close to 0,\n",
    "but not be exactly sure what it is.\n",
    "\n",
    "We can use the same distribution to represent our beliefs about the true mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "f, ax, = plt.subplots(figsize=(12, 6))\n",
    "xs = np.linspace(-5, 5, 1000)\n",
    "ax.plot(xs, standard_normal_distribution(xs), lw=4);\n",
    "ax.set_xlabel(\"Value Claimed for True Mean of Brain Wave Amplitude\");\n",
    "ax.set_ylabel(\"Proportional to Plausibility\\nof Claim True Mean is Value\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Now that the distribution is representing something we don't observe,\n",
    "it is instead saying that\n",
    "it is _very implausible_ that the true value is around 3,\n",
    "while it is _more plausible_ that the true value is around 1\n",
    "and _even more plausible_ that the true value is around 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Or, more generally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "f, ax, = plt.subplots(figsize=(12, 6))\n",
    "xs = np.linspace(-5, 5, 1000)\n",
    "ax.plot(xs, standard_normal_distribution(xs), lw=4);\n",
    "ax.set_xlabel(\"Value Claimed\"); ax.set_ylabel(\"Proportional to\\nPlausibility of Claim\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## This type of random variable most often appears in the _prior_ of our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The _prior_ is the piece of our model that describes which values of certain unknown quantities,\n",
    "usually parameters, we think are _a priori_ plausible or implausible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Both the _long-run frequency of an event_ and the _plausibility of a claim_ are things we can call _probabilities_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A claim that is more plausible is _more likely to be true_ or _more probable_;\n",
    "and event that occurs more often is _more likely to occur_ or _more probable_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## We can make both kinds of random variables in pyMC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "First, let's make a model with two random variables in it:\n",
    "one for the true mean of the data\n",
    "and the other for the observed values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model() as model:\n",
    "    true_mean = pm.Normal(\"mu\", mu=0, sd=1)\n",
    "    X = pm.Normal(\"X\", mu=true_mean, sd=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The random variable `X` is not a `pm.Distribution`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "isinstance(X, pm.Distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "It is a type of random variable (`RV`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "isinstance(X, pm.model.FreeRV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We add random variables to a pyMC model mostly by telling pyMC what `Distribution` function to use for that variable,\n",
    "including its parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "There are other types of `RV`s.\n",
    "\n",
    "For example, we've often said that some things have been `observed`,\n",
    "and so we know some values they took on.\n",
    "\n",
    "These are called `ObservedRV`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model() as model:\n",
    "    true_mean = pm.Normal(\"mu\", mu=0, sd=1)\n",
    "    observed_X = pm.Normal(\"X\", mu=true_mean, sd=1, observed=3.14159)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "isinstance(observed_X, pm.model.FreeRV), isinstance(observed_X, pm.model.ObservedRV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The closest thing to a general type for all `RV`s in this version of pyMC\n",
    "is a `Factor`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "isinstance(true_mean, pm.Factor), isinstance(observed_X, pm.Factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# But why make models?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "You might find yourself asking a similar question as Zoolander et al., 2001:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "display.Image(\"img/why_make_models.gif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "From the movie [_Zoolander_](https://en.wikipedia.org/wiki/Zoolander)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Two main purposes for building models are"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### to *simulate a process* whose outcomes are random, and"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### to *quantify our uncertainty* about claims."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Let's work through some examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## We can model to simulate a process whose outcomes are random."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Or, more generally, **to describe complicated probability distributions as the combination and transformation of their parts**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "  - DnD: combinations and transformations of uniforms (lab03)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "  - Sampling distribution of data: the distribution of the values of my data samples (lec02, lec04)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "  - Sampling distribution of statistic: the distribution of the values of statistics computed from data samples (lec04)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Can you think of any other examples from the lectures, homework, or labs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### For example, we might know the distributions of two groups and want to know what the distribution of differences looks like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "These might be scores of two groups on a task,\n",
    "or amplitudes of brain waves of people doing two different things,\n",
    "and we want to know what the difference between two individual values is likely to be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's consider the case of brain wave amplitudes for people performing different tasks.\n",
    "In particular, let's say that the participants are either focusing on their breathing,\n",
    "as in the examples above, or they are internally recalling a story."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "This example is based on\n",
    "[this paper](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7320143)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Presume that all of the parameters for this data are known:\n",
    "the true means and standard deviations of the brain wave amplitudes\n",
    "measured from both groups of people.\n",
    "\n",
    "For simplicitly, say the means are `0` and `1`, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The model below will simulate data that might be measured in an experiment\n",
    "where we subtract the brain wave amplitude from a subject who is focusing on breathing\n",
    "from the same from a subject internally telling a story,\n",
    "given all of the assumptions above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model() as model:\n",
    "    # all the parameters are known\n",
    "    # parameters for group 0: focusing on breathing\n",
    "    mu_0 = 0; sd_0 = 1\n",
    "    # parameters for group 1: internal monologue\n",
    "    mu_1 = 1; sd_1 = 1\n",
    "    \n",
    "    # random variable for observed brain wave amplitudes\n",
    "    #  for participant focusing on breathing\n",
    "    x_0 = pm.Normal(\"x_0\", mu=mu_0, sd=sd_0)\n",
    "    \n",
    "    # andom variable of observed brain wave amplitudes\n",
    "    #  for participant internally telling a story\n",
    "    x_1 = pm.Normal(\"x_1\", mu=mu_1, sd=sd_1)\n",
    "    \n",
    "    # random variable for distribution of differences\n",
    "    delta_x = pm.Deterministic(\"delta_x\", x_1 - x_0)\n",
    "    \n",
    "type(mu_0), type(x_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Notice that some parts of the model are normal Python variables,\n",
    "like the known values of the parameters, e.g. `mu_0`,\n",
    "while other parts of the model are `pymc` random variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "When we call `pm.sample`,\n",
    "values of `x_0` and `x_1` are drawn according to the distributions provided in the model,\n",
    "and then `delta_x` is computed for each sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "samples = shared_util.samples_to_dataframe(shared_util.sample_from(model))\n",
    "\n",
    "samples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(18, 12))\n",
    "sns.distplot(samples[\"delta_x\"]); plt.title(\"Sampling Distribution of delta_x\\nFor Given Assumptions\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## For this kind of modeling, we do not _need_ pyMC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In fact, we can use just use functions from the Python standard library, in particular the `random` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# note the similarity here: we pick a fixed value for the parameters\n",
    "mu_0 = 0; mu_1 = 1; sd_0 = 1; sd_1 = 1\n",
    "\n",
    "# note the similarity here: we pick a distriubtion for the values\n",
    "x_0 = pd.Series([random.normalvariate(mu=mu_0, sigma=sd_0) for _ in range(1000)])\n",
    "x_1 = pd.Series([random.normalvariate(mu=mu_1, sigma=sd_1) for _ in range(1000)])\n",
    "\n",
    "delta_x = x_1 - x_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "python_samples = pd.DataFrame({\"x_0\": x_0, \"x_1\": x_1, \"delta_x\": delta_x})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_samples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(figsize=(18, 12), nrows=2, sharex=True, sharey=True)\n",
    "sns.distplot(samples[\"delta_x\"], label=\"pyMC Samples\", axlabel=False, ax=axs[0]); axs[0].legend()\n",
    "sns.distplot(python_samples[\"delta_x\"], label=\"Python stdlib Samples\", ax=axs[1], color=\"C1\"); axs[1].legend()\n",
    "axs[0].set_title(\"Sampling Distribution of delta_x\\nFor Given Assumptions\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Using pyMC for something like this, though possible, is unwise,\n",
    "like the activity depicted in the video below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display.YouTubeVideo(\"ep9LZyF2fPA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "That is, pyMC is not quite the right tool for this job:\n",
    "it is designed for something much harder.\n",
    "\n",
    "So when and why do we need pyMC?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Writing down a model this detailed requires lots of knowledge!\n",
    "\n",
    "We are not usually in the setting where we can do so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For a board game, we know all of the rules and so can build an exact model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For a real life problem, we don't know everything:\n",
    "we don't know the actual means and standard deviations.\n",
    "\n",
    "We can measure them on samples,\n",
    "but we _know those values will be wrong_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Null models, or models of the null hypothesis,\n",
    "are an interesting example of a workaround.\n",
    "\n",
    "Instead of specifying that we know the true values,\n",
    "we \"pretend\" to claim or hypothesize that the true values\n",
    "are some uninteresting values.\n",
    "\n",
    "This allows us to see <i>a</i> sampling distribution of the data,\n",
    "or a statistic, but we don't know that it's _the_ sampling distribution,\n",
    "as in the correct one, and so it doesn't make for a good simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model() as null_model:\n",
    "    mu_0 = 0; mu_1 = 0;  # means are the same: uninteresting\n",
    "    shared_sd = 1  # standard deviations are also the same\n",
    "    \n",
    "    x_0 = pm.Normal(\"x_0\", mu=mu_0, sd=shared_sd)\n",
    "    x_1 = pm.Normal(\"x_1\", mu=mu_1, sd=shared_sd)\n",
    "    \n",
    "    delta_x = pm.Deterministic(\"delta_x\", x_1 - x_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "null_samples = shared_util.samples_to_dataframe(shared_util.sample_from(null_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(figsize=(12, 12), nrows=2, sharex=True, sharey=True)\n",
    "sns.distplot(null_samples[\"delta_x\"], ax=axs[0], label=\"pyMC Null Samples\",color=\"C0\", axlabel=False);\n",
    "sns.distplot(python_samples[\"delta_x\"], ax=axs[1], color=\"C1\", label=\"Python stdlib Samples\");\n",
    "axs[0].legend(); axs[1].legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We want to use what we measured on a sample\n",
    "to determine _what values are plausible_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## We need pyMC when we model to quantify our uncertainty.\n",
    "\n",
    "Specifically to quantify our uncertainty about things we cannot measure, once we've measured related things."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "  - **\"Effect of\" task difficulty on score**, aka average score of participants on tasks with different difficulty (lec07)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "  - **Relationship between generation and emoji use** (lab07)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Can you think of any other examples from the lectures, homework, or labs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### For example, we can use pyMC to guess what the mean is if we know what the data _would_ look like _if only_ we knew the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In our running brain waves example,\n",
    "this corresponds to the (more realistic)\n",
    "case where we don't know what the true means are,\n",
    "but we do know or assume that the data would be Normal\n",
    "around that true mean.\n",
    "\n",
    "To start, let's say we know that the mean is _either_ 0 _or_ it is 1.\n",
    "\n",
    "No other values are possible.\n",
    "\n",
    "For example, we might know that the means of the two participant groups are `0` and `1`,\n",
    "and we want to infer whether a particular value or set of values we observed\n",
    "came from one group or the other.\n",
    "\n",
    "Perhaps we are trying to prove that the brain wave measurements can be used to predict\n",
    "whether the person is thinking about their breathing or about a story -- a limited form of mind-reading."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "For a more advanced approach to the same idea, see\n",
    "[Naselaris et al., 2009](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5553889/),\n",
    "_Bayesian reconstruction of natural umages from human brian activity_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model() as du_model:\n",
    "    # Our belief: the unknown true mean of the variable X either 0 or 1\n",
    "    #   the actual value is fixed, but unknown\n",
    "    mu = pm.DiscreteUniform(\"true_mean\", lower=0, upper=1)\n",
    "    \n",
    "    # Frequencies: the frequency of observing values of X drops off\n",
    "    #  like a bell curve around its mean\n",
    "    X = pm.Normal(\"brain_wave_amplitude\", mu=mu, sd=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "For now, we are _not_ including any observed values,\n",
    "we're just writing down the general form of the model and taking a look at it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "When we draw samples from this model,\n",
    "all of the free random variables\n",
    "will take on different values, according to their distributions.\n",
    "\n",
    "The details are more complicated, but you might think of it this way:\n",
    "first pyMC flips a coin to determine whether `mu` is `0` or `1`.\n",
    "Then, that value of `mu` is used to determine the mean of the normal distribution\n",
    "according to which `X` is drawn.\n",
    "This is repeated over and over again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "du_samples = shared_util.samples_to_dataframe(shared_util.sample_from(du_model, draws=5000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "du_samples[\"true_mean\"].value_counts() / len(du_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "[sns.distplot(samp, ax=ax, label=f\"Samples When True Mean is {i}\")\n",
    " for i, samp in du_samples.groupby(\"true_mean\")[\"brain_wave_amplitude\"]];\n",
    "plt.ylim(*1.4 * np.array(plt.ylim()));ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "sns.distplot(du_samples[\"brain_wave_amplitude\"], label=\"All Samples Together\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "In the real world, this is _not_ the frequency of values we'd expect to see!\n",
    "\n",
    "We'd expect to see _either_ the distribution on the left\n",
    "_or_ the distribution on the right,\n",
    "but not this mixture of the two."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The plot below shows the two distributions\n",
    "along with some data we might have measured\n",
    "from a participant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "possible_observations = [0.5, 1, -2]\n",
    "\n",
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "[sns.distplot(samp, ax=ax, label=f\"Samples When True Mean is {i}\")\n",
    " for i, samp in du_samples.groupby(\"true_mean\")[\"brain_wave_amplitude\"]];\n",
    "ax.vlines(possible_observations, 0, 0.3, lw=4, label=\"Possible Observed Values\");\n",
    "plt.ylim(*1.5 * np.array(plt.ylim())); ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "For each of the possible observed values,\n",
    "which of the two distributions was it more likely to be drawn from?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "In responding to that question,\n",
    "we base our answers on $p(\\text{data}\\vert\\text{parameters})$,\n",
    "the _likelihood_ part of the model.\n",
    "\n",
    "By selecting out samples that all share the same value for the parameters,\n",
    "we are visualizing this likelihood component."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Given the three observed values,\n",
    "do you think the mean is more likely to be 0 or 1?\n",
    "\n",
    "HINT: you can test your guess by feeding the values to the model `du_model_with_obs` below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## pyMC gives us access to $p(\\text{parameters}\\vert\\text{data})$, the _posterior_ of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The important question, though, isn't $p(\\text{data}\\vert\\text{parameters})$,\n",
    "it's $p(\\text{parameters}\\vert\\text{data})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "That is, not "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "which _data values_ will be observed more frequently, for this value of the _parameters_,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "but "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "which claims about the values of the _parameters_ are more plausible,\n",
    "given I observed these _data values_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "This is generally the way the world works:\n",
    "we make internal mental models or mathematical models or computer models that can tell us\n",
    "how a system will behave _if we know the right things_,\n",
    "but then we almost never actually _get to know the right things_,\n",
    "so we have to _infer_ or _guess_ those values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## This posterior is the distribution corresponding to our uncertainty about the unknown values, once we have observed other values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## To get a posterior, pyMC needs to know two things: a _prior_ and a _likelihood_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### The _prior_ is the distribution of the random variables corresponding to the unknown values that we write into our pyMC model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "It specifies, _a priori_ or _before we see anything_,\n",
    "the plausibility of all claims about the unknown values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\n",
    "p(\\texttt{mu})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### The _likelihood_ is with what frequency we'd observe different values of the data, _if_ the parameters were some fixed value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\n",
    "p(\\text{data} \\vert \\texttt{mu})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Unlike the prior and the likelihood, the distribution of the posterior is not specified by us, nor is its mathematical form known to pyMC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Individual values can be calculated, up to a proportionality constant,\n",
    "from the prior and the likelihood:\n",
    "\n",
    "$$\n",
    "p(\\texttt{mu} \\vert \\text{data}) \\propto p(\\text{data}\\vert\\mu)p(\\texttt{mu})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "This relationship is obtained from Bayes' Rule,\n",
    "and that's why this approach is called a _Bayesian_ approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Instead we _estimate_ the posterior based on samples, drawn with `pm.sample`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model() as du_model_with_obs:\n",
    "    # Our belief: the unknown true mean of the variable X either 0 or 1\n",
    "    #   the actual value is fixed, but unknown\n",
    "    mu = pm.DiscreteUniform(\"true_mean\", lower=0, upper=1)\n",
    "    \n",
    "    # Frequencies: the frequency of observing values of X drops off\n",
    "    #  like a bell curve around its mean\n",
    "    X = pm.Normal(\"brain_wave_amplitude\", mu=mu, sd=1, observed=[0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "post_samples = shared_util.samples_to_dataframe(shared_util.sample_from(du_model_with_obs, draws=5000))\n",
    "\n",
    "post_samples[\"true_mean\"].value_counts() / len(post_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Try providing each of the `possible_observations` above to this model and computing the posterior.\n",
    "\n",
    "Beforehand, try and guess which of the two claims -- that the mean is 0 or that the mean is 1 -- is more plausible _given the observed value_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Typically,\n",
    "we aren't in a world where only one of two possibilities is true.\n",
    "\n",
    "Instead, there are an infinite number of possibilities.\n",
    "\n",
    "For example, say we thought the true mean was _between_ 0 and 1,\n",
    "rather then being _equal to_ 0 or 1.\n",
    "\n",
    "Now, there are infinitely many possibilities: $0, 1/2, 1/4, 3/4, ...$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "So we can't visualize the likelihood the same way:\n",
    "all of our samples will have _different values for the true mean_.\n",
    "\n",
    "And our prior and posterior will be best viewed as histograms,\n",
    "rather than as frequencies for all of the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model() as unif_model_obs:\n",
    "    # Our belief: the unknown true mean of the variable X between 0 and 1\n",
    "    mu = pm.Uniform(\"true_mean\", lower=0, upper=1)\n",
    "    \n",
    "    # Frequencies: the frequency of observing values of X drops off\n",
    "    #  like a bell curve around its (unknown!) mean\n",
    "    X = pm.Normal(\"brain_wave_amplitude\", mu=mu, sd=1, observed=[0.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Remember that we can use `pm.sample_prior_predictive`\n",
    "if we want to see what the prior looks like\n",
    "for a model with `observed` variables in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "prior_samples = shared_util.samples_to_dataframe(pm.sample_prior_predictive(model=unif_model_obs, samples=10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "post_samples = shared_util.samples_to_dataframe(shared_util.sample_from(unif_model_obs, draws=5000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(figsize=(12, 6), ncols=2, sharex=True, sharey=True)\n",
    "sns.distplot(prior_samples[\"true_mean\"], ax=axs[0], label=\"Prior\");\n",
    "sns.distplot(post_samples[\"true_mean\"], ax=axs[1], label=\"Posterior\", color=\"C2\");\n",
    "axs[0].set_ylabel(\"Plausibility of Claim that\\nTrue Mean is Value on x-Axis\")\n",
    "[ax.legend() for ax in axs];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The distribution on the right approximates $p(\\texttt{mu} \\vert \\text{data})$\n",
    "for every possible value of the true mean (along the x-axis):\n",
    "the plausibility, given the $\\text{data}$ we observed,\n",
    "of the claim that the parameter `mu` is equal to the value on the x-axis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Remember that the posterior is obtained using the proportion we got from Bayes' Rule:\n",
    "\n",
    "$$\n",
    "p(\\texttt{mu} \\vert \\text{data}) \\propto p(\\text{data}\\vert\\mu)p(\\texttt{mu})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "And note that since we used a `Uniform` prior, we have just\n",
    "$$\n",
    "p(\\texttt{mu} \\vert \\text{data}) \\propto p(\\text{data}\\vert\\texttt{mu})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "It's usually pretty hard to tell the difference between our beliefs before and after seeing a value of `0.5`.\n",
    "You might notice that the posterior is \"bulging\" upwards in the middle and lower at the edges.\n",
    "\n",
    "Change the value observed to a more extreme value:\n",
    "`0.9`, or `2`, or `10`.\n",
    "try and predict what the shape of the posterior will be in each case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The section below shows the same procedure,\n",
    "but for a `Normal` prior,\n",
    "which has shown up more often in the class this far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model() as normal_model:\n",
    "    # Our belief: the unknown true mean of the variable X close to 0, 1\n",
    "    mu = pm.Normal(\"true_mean\", mu=0, sd=1)\n",
    "    \n",
    "    # Frequencies: the frequency of observing values of X drops off\n",
    "    #  like a bell curve around its mean\n",
    "    X = pm.Normal(\"brain_wave_amplitude\", mu=mu, sd=1, observed=[0, 1, 3, 2, 1.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "prior_samples = pm.sample_prior_predictive(model=normal_model, samples=10000)\n",
    "post_samples = shared_util.samples_to_dataframe(shared_util.sample_from(normal_model, draws=5000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "sns.distplot(prior_samples[\"true_mean\"], label=\"Prior\");\n",
    "sns.distplot(post_samples[\"true_mean\"], label=\"Posterior\", color=\"C2\");\n",
    "ax.set_ylabel(\"Plausibility of Claim that\\nTrue Mean is Value on x-Axis\"); ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Graphical Perspective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "When we make graphs,\n",
    "we draw a circle, or _node_, for each of our variables\n",
    "and then we draw an arrow, or _edge_, to mean\n",
    "\"the variable at the tail is used to set the distribution of the variable at the tip\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "These graphs are partial descriptions of pyMC models.\n",
    "\n",
    "As descriptions, they capture the overall structure:\n",
    "which variables are present,\n",
    "who determines whose values, what values are known,\n",
    "what values are unknown.\n",
    "\n",
    "They are _partial_ because they don't capture which distributions are in play.\n",
    "\n",
    "All of the models in the section on modeling to quantify our uncertainty\n",
    "have the same graph, the one below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "params_known = False; data_known = True\n",
    "\n",
    "data_node = daft.Node(\"brain\\nwave\\ndata\", \"brain\\nwave\\ndata\", 4, 1, scale=4, observed=data_known);\n",
    "params_node = daft.Node(\"mu\", \"mu\", 1, 1, scale=4, observed=params_known)\n",
    "\n",
    "pgm = daft.PGM([6, 2]); pgm.add_node(data_node); pgm.add_node(params_node);\n",
    "pgm.add_edge(\"mu\", \"brain\\nwave\\ndata\", head_width=0.25, lw=3)\n",
    "\n",
    "pgm.render();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "That is, we have observed the brain wave data,\n",
    "and we know that the distribution of the brain wave amplitudes depends on the values of the parameter, `mu`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "When we create a model to simulate our data,\n",
    "the structure of the model is often similar,\n",
    "but with one important difference:\n",
    "the node colored in is different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "params_known = True; data_known = False\n",
    "\n",
    "data_node = daft.Node(\"brain\\nwave\\ndata\", \"brain\\nwave\\ndata\", 4, 1, scale=4, observed=data_known);\n",
    "params_node = daft.Node(\"mu\", \"mu\", 1, 1, scale=4, observed=params_known)\n",
    "\n",
    "pgm = daft.PGM([6, 2]); pgm.add_node(data_node); pgm.add_node(params_node);\n",
    "pgm.add_edge(\"mu\", \"brain\\nwave\\ndata\", head_width=0.25, lw=3)\n",
    "\n",
    "pgm.render();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "That is, we are presuming that the parameters are _known_,\n",
    "since these are the parameters we give the model,\n",
    "while the data is unknown, since that's the output of our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Given our definition of the arrows,\n",
    "\"the value at the tail is used to determine the value at the tip\",\n",
    "we can loosely specify when pyMC is useful and when it is not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Whenever there are _no unknown values determining any known values_,\n",
    "we don't need pyMC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Another way of putting it:\n",
    "whenever the information from our observations only flows _forward along arrows_,\n",
    "never backwards,\n",
    "we don't need pyMC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Anatomy of a Bayesian Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```python\n",
    "with pm.Model() as model:\n",
    "    # Prior/Pre-Experiment Beliefs:\n",
    "    #   Create random variables for all unknown, unobservable parameters\n",
    "    param0 = pm.?(\"param1\", hyperparam0=?, ...)\n",
    "    ...\n",
    "    paramN = pm.?(\"paramN\", hyperparam0=?, ...)\n",
    "    \n",
    "    # Likelihood:\n",
    "    #   Create random variable for values we have observed\n",
    "    #   and use RVs from prior to set parameter\n",
    "    #   and tell pyMC which values you've observed\n",
    "    observable_value = pm.?(\"observable_value\",\n",
    "                            likelihood_param0=param0, ..., observed=?)\n",
    "    \n",
    "with model:\n",
    "    # approximate posterior by drawing samples\n",
    "    posterior_samples = pm.sample(...)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Make sure you can identify each of the pieces above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Prior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Random variables with associated distributions <br><br>\n",
    "\n",
    "- Represent our prior knowledge or beliefs before observing data, typically about parameters of likelihood <br><br>\n",
    "\n",
    "- Randomness used to represent uncertainty in truth of claims about certain variables <br><br>\n",
    "\n",
    "- Partially subjective -- different modelers believe or know different things"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Random variable(s) with associated distribution(s) <br><br>\n",
    "\n",
    "- Represent what data distribution would look like, if we knew parameters <br><br>\n",
    "\n",
    "- Randomness used to represent variability from observation to observation due to uncontrolled variables not in prior <br><br>\n",
    "\n",
    "- Less subjective than prior, but still a modeling choice and reliant on our knowledge of the domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Concrete Python values (often a `Series`) <br><br>\n",
    "\n",
    "- Measured out in the world <br><br>\n",
    "\n",
    "- Fed to model via the likelihood component with `observed` keyword"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Represented approximately with samples (comes out of pyMC as a `MultiTrace`, but we convert to a `DataFrame`) <br><br>\n",
    "\n",
    "- Knowing posterior is the goal of modeling: knowing what we believe about unknown things, given what we observed (observations) and what we knew beforehand (prior, likelihood)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Graphically, the _prior_ is associated with the nodes for the unknown parameters (nodes without color).\n",
    "\n",
    "The _likelihood_ is associated with the arrows connecting the parameter nodes and the observed nodes (nodes with color) and with the nodes themselves.\n",
    "\n",
    "The _observations_ are what make some nodes colored in. Without observations, a node is without color.\n",
    "\n",
    "The _posterior_ is also associated with the nodes for the unknown parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "params_known = False; data_known = True\n",
    "\n",
    "data_node = daft.Node(\"brain\\nwave\\ndata\", \"brain\\nwave\\ndata\", 4, 1, scale=4, observed=data_known);\n",
    "params_node = daft.Node(\"mu\", \"mu\", 1, 1, scale=4, observed=params_known)\n",
    "\n",
    "pgm = daft.PGM([6, 2]); pgm.add_node(data_node); pgm.add_node(params_node);\n",
    "pgm.add_edge(\"mu\", \"brain\\nwave\\ndata\", head_width=0.25, lw=3)\n",
    "\n",
    "pgm.render();"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
